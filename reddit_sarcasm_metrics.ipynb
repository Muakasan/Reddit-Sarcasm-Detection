{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in CSVs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/preprocessing/text.py:145: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted Tokenizer to text\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def comments_to_seq2(c):\n",
    "    seq = [[np.asarray(\n",
    "        [0 if \"...\" in x else 1,\n",
    "        0 if x.upper() == x else 1,\n",
    "        0 if \"!\" in x else 1])\n",
    "        for x in comment.split(\" \")] for comment in c]\n",
    "    return seq\n",
    "\n",
    "MAX_NB_WORDS = 50000 #50000 unique words?\n",
    "MAX_SEQUENCE_LENGTH = 30 #30 word sentences?\n",
    "\n",
    "key_df =pd.read_csv('data/key.csv', sep='\\t')\n",
    "train_df = pd.read_csv('data/train-balanced.csv', sep='\\t', header=None, names=list(key_df))\n",
    "tweet_df = pd.read_csv('clean_tweet_data.tsv', sep='\\t')\n",
    "print(\"Read in CSVs\")\n",
    "comments = [str(x) for x in list(train_df[\"comment\"])] #add in parent comment later\n",
    "tokenizer = Tokenizer(nb_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(comments)\n",
    "print(\"Fitted Tokenizer to text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ..., 0 0 0]\n",
      "[0 1 0 ..., 0 0 0]\n",
      "Hashtag scores:\n",
      "Precision: 0.666666666667\n",
      "Recall: 0.229787234043\n",
      "F1: 0.341772151899\n",
      "1888/1984 [===========================>..] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b[0.73317524502354281, 0.58064516129032262]\n",
      "['loss', 'acc']\n",
      "Annotated scores:\n",
      "Precision: 0.172839506173\n",
      "Recall: 0.172839506173\n",
      "F1: 0.172839506173\n",
      "1760/1984 [=========================>....] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b[0.57722676665552197, 0.72983870967741937]\n",
      "['loss', 'acc']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "input_comments = [str(x) for x in list(tweet_df[\"clean_tweet_text\"])]\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(input_comments)\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "data2 = pad_sequences(comments_to_seq2(input_comments), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "model = load_model(\"large_feature_model_2.h5\")\n",
    "\n",
    "\n",
    "st_ser = tweet_df['tweet_text'].str.contains(\"#sarcasm|#sarcastic\", flags=re.IGNORECASE)\n",
    "labels_bin_hash = [1 if x else 0 for x in st_ser]\n",
    "labels_hash = to_categorical(labels_bin_hash)\n",
    "\n",
    "labels_bin = np.asarray(tweet_df[\"sarcastic\"])\n",
    "\n",
    "results = model.predict(x=[data, data2])\n",
    "y_predict = np.asarray([np.argmax(x) for x in results])\n",
    "print(labels_bin)\n",
    "print(y_predict)\n",
    "\n",
    "print(\"Hashtag scores:\")\n",
    "print(\"Precision:\", precision_score(labels_bin_hash, y_predict))\n",
    "print(\"Recall:\", recall_score(labels_bin_hash, y_predict))\n",
    "print(\"F1:\", f1_score(labels_bin_hash, y_predict))\n",
    "\n",
    "print(model.evaluate(x=[data, data2], y=labels_hash))\n",
    "print(model.metrics_names)\n",
    "\n",
    "print(\"Annotated scores:\")\n",
    "print(\"Precision:\", precision_score(labels_bin, y_predict))\n",
    "print(\"Recall:\", recall_score(labels_bin, y_predict))\n",
    "print(\"F1:\", f1_score(labels_bin, y_predict))\n",
    "\n",
    "print(model.evaluate(x=[data, data2], y=labels))\n",
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.751416769855\n",
      "Recall: 0.660837493243\n",
      "F1: 0.703222341114\n",
      "[0 0 0 ..., 1 1 1]\n",
      "[0 1 0 ..., 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('data/test-balanced.csv', sep='\\t', header=None, names=list(key_df))\n",
    "test_comments = [str(x) for x in list(test_df[\"comment\"])] \n",
    "\n",
    "sequences_test = tokenizer.texts_to_sequences(test_comments)\n",
    "\n",
    "data_test = pad_sequences(sequences_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "data2_test = pad_sequences(comments_to_seq2(test_comments), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "labels_bin_test = np.asarray(test_df[\"label\"])\n",
    "\n",
    "results_test = model.predict(x=[data_test, data2_test])\n",
    "y_predict_test = np.asarray([np.argmax(x) for x in results_test])\n",
    "\n",
    "print(\"Precision:\", precision_score(labels_bin_test, y_predict_test))\n",
    "print(\"Recall:\", recall_score(labels_bin_test, y_predict_test))\n",
    "print(\"F1:\", f1_score(labels_bin_test, y_predict_test))\n",
    "\n",
    "print(labels_bin_test)\n",
    "print(y_predict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 50\n",
    "len(tweet_df[tweet_df[\"sarcastic\"] == 1][\"clean_tweet_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "sarcastic_predicted_indices = []\n",
    "for i in range(len(y_predict)):\n",
    "    if y_predict[i] == 1:\n",
    "        sarcastic_predicted_indices.append(i)\n",
    "s_df = tweet_df.iloc[sarcastic_predicted_indices]\n",
    "s_ser = s_df['tweet_text'].str.contains(\"#sarcasm|#sarcastic\", flags=re.IGNORECASE)\n",
    "s_ar = np.asarray(s_ser)\n",
    "(s_ar == True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
